{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "try:\n",
    "    import _pickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "from dateutil import relativedelta\n",
    "from urllib import request\n",
    "\n",
    "from typing import List, Text, Callable, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, json) -> None:\n",
    "        self.game_id = json['game']\n",
    "        self.player_count = json['player_count']\n",
    "        self.total_vp = json['events']['faction']['all']['vp']['round']['all']\n",
    "        \n",
    "    def averageVPPerPlayer(self) -> float:\n",
    "        return self.total_vp / self.player_count\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return \"\"\"\n",
    "        Game: %s\n",
    "        Players: %s\n",
    "        Total VP: %s\n",
    "        \"\"\" % (self.game_id, self.player_count, self.total_vp)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchAllSummaryData(minDate: datetime.datetime, maxDate: datetime.datetime,\n",
    "                       keepPredicate: Callable[[Game], bool], local: bool = False,\n",
    "                       maxGames: Optional[int]=None) -> List[Game]:\n",
    "    \"\"\"Fetches the Games based on summary data.\n",
    "    \n",
    "    Args:\n",
    "        minDate: The smallest date from which to fetch games (only the month matters)\n",
    "        maxDate: The largest date from which to fetch games (only the month matters)\n",
    "        keepPredicate: A callable. For memory efficiency, we can push down filtering on games\n",
    "            using this function. If this function returns true, the Game is kept. Otherwise\n",
    "            it is immediately discared.\n",
    "        maxGames: The maximum number of games to return. Games are retrieved from latest to\n",
    "            oldest, date wise.\n",
    "    \n",
    "    Returns:\n",
    "        A list of Game objects fetched from Terra Snellman.\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://terra.snellman.net/data/events\"\n",
    "    results: List[Game] = []\n",
    "    while minDate < maxDate and (not maxGames or len(results) < maxGames):\n",
    "        filename = \"snellman/summary-%s.pkl\" % (maxDate.strftime(\"%Y-%m\"))\n",
    "        address = \"{}/{}.json\".format(BASE_URL, maxDate.strftime(\"%Y-%m\"))\n",
    "        data = None\n",
    "        if not local:\n",
    "            try:\n",
    "                with request.urlopen(address) as site:\n",
    "                    data = json.loads(site.read().decode())\n",
    "            except:\n",
    "                maxDate -= relativedelta.relativedelta(months=1)\n",
    "                continue\n",
    "            with open(\"snellman/summary-%s.pkl\" % (maxDate.strftime(\"%Y-%m\")) , 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "        else:\n",
    "            with open(filename, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "        prevNGames = len(results) \n",
    "        for obj in data:\n",
    "            game = Game(obj)\n",
    "            if keepPredicate(game):\n",
    "                results.append(game)\n",
    "        del data\n",
    "        maxDate -= relativedelta.relativedelta(months=1)\n",
    "        print(\"Collected %s games from %s.\" % (len(results), address))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepHighScoringGames(game: Game) -> bool:\n",
    "    return game.averageVPPerPlayer() > 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadLogForGameAsSentence(game: Game) -> Text:\n",
    "    kBaseUrl = \"https://terra.snellman.net/app/view-game/\"\n",
    "    res = requests.post(kBaseUrl, data={'game': game.game_id})\n",
    "    data = json.loads(res.content)\n",
    "    commands = [command['commands'].split(\".\")\n",
    "                for command in data['ledger']\n",
    "                if 'commands' in command]\n",
    "    gameSentence = \" \".join(item.strip()\n",
    "                            for sublist in commands\n",
    "                            for item in sublist)\n",
    "    return gameSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchAllGameSetences(local: bool = False, saveEvery:int=1000):\n",
    "    \"\"\"Downloads game data and dumps to disk.\n",
    "    \"\"\"\n",
    "    OLDEST_DATE = datetime.datetime(year=2013, month=1,day=15)\n",
    "    NEWEST_DATE = datetime.datetime.now()\n",
    "    data = fetchAllSummaryData(OLDEST_DATE, NEWEST_DATE,\n",
    "                               keepPredicate=keepHighScoringGames,\n",
    "                               maxGames=20000, local=local)\n",
    "    sentences = []\n",
    "    if not local:\n",
    "        for i, game in enumerate(data):\n",
    "            sentence = downloadLogForGameAsSentence(game)\n",
    "            sentences.append(sentence)\n",
    "            if i + 1 % saveEvery == 0:\n",
    "                with open('snellman/sentences-%s-of-%s.pkl' % (i, len(data)), 'wb') as f:\n",
    "                    pickle.dump(sentences, f)\n",
    "                del sentences\n",
    "                senteces = []\n",
    "    # Load it from disk.\n",
    "    text = \"\"\n",
    "    for i, game in range(0, len(data), saveEvery):\n",
    "        with open('snellman/sentences-%s-of-%s.pkl' % (i, len(data)), 'rb') as f:\n",
    "            text += \"\\n\".join(pickle.load(f))\n",
    "    return text\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 965 games from https://terra.snellman.net/data/events/2019-01.json.\n",
      "Collected 1768 games from https://terra.snellman.net/data/events/2018-12.json.\n",
      "Collected 2620 games from https://terra.snellman.net/data/events/2018-11.json.\n",
      "Collected 3524 games from https://terra.snellman.net/data/events/2018-10.json.\n",
      "Collected 4444 games from https://terra.snellman.net/data/events/2018-09.json.\n",
      "Collected 5369 games from https://terra.snellman.net/data/events/2018-08.json.\n",
      "Collected 6333 games from https://terra.snellman.net/data/events/2018-07.json.\n",
      "Collected 7286 games from https://terra.snellman.net/data/events/2018-06.json.\n",
      "Collected 8337 games from https://terra.snellman.net/data/events/2018-05.json.\n"
     ]
    }
   ],
   "source": [
    "with open(\"snellman/games.input\", \"w\") as f:\n",
    "    f.write(fetchAllGameSetences(local=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terra-ai",
   "language": "python",
   "name": "terra-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
